---
title: "Functions"
format: html
editor: visual
---

*You can edit this however you like. I just put the instructions on the page so I wouldn't have to toggle* No worries I figure we can focus on the code and clean up the explanation toward the end. I am still going to try and explain as I go so you/I don't get lost but it may not be the most poetic writing.

# Creating the Functions used on this Project

## Querying the Census API and returning a table

### Quoted string

Creating a function to call on specified variables from the Census API. Method: passing along variables to a paste statement based on the following specifications

-   Contains a year between 2010-2022

-   Return at least 2 numeric variables: PUMS person weight (PWGTP) and at least 1 of the following

    -   Age (AGEP), Gas Cost (GASP), Gross rent as a percentage of household income (GRPIP), Time of arrival at work (JWAP), Time of departure from work (JWDP), Travel time to work (JWMNP)

-   Return at least 1 categorical variable

    -   (FER), (HHL), (HISPEED), (JWTRNS), (SCH), (SCHL), (SEX)

-   Optional argument to subset the data based on geography (All, Regions, Divisions, or States)

Setting up the needed packages for this project. Note please make sure you install these packages in your console before calling them with the library statement!

```{r}
# Libraries we need 
# For building function
library("tidyverse")
# To query API
library("httr")
library("jsonlite")
```

The first step in our homework is to try and query an API. I chose a random URL to test before we get into our function writing.

```{r}
# "Start by getting the usual process to work with a given URL"
# I am setting up trial url
test_URL <- "https://api.census.gov/data/2012/acs/acs1/pumspr?get=SEX,PWGTP,MAR&SCHL=24"
raw_info <-GET(test_URL)
parsed <- fromJSON(rawToChar(raw_info$content))
# The first row is column names so we have to adjust 
test_info <- as_tibble(parsed[-1,])
colnames(test_info) <- parsed[1,] 
test_info
```

If you click on the link it looks like our code worked great! Let's work on the second step, writing a helper function to iterate this process.

```{r}
# "Write a helper function to take what is returned by GET() and turn it into a nice tibble"
# This assumes valid URL is used and has the same structure as our above example if our other function is thurough enough
# then this should not be an issue. 
URL_funct <-function(Census_URL){ 
  raw_info <-GET(Census_URL)
  parsed <-fromJSON(rawToChar(raw_info$content))
  Census_info <- as_tibble(parsed[-1,])
  colnames(Census_info) <- parsed[1,] 
  return(Census_info)
}
```

```{r}
query_api <- function(year=2022, vars = c("PWGTP"=NA, "AGEP"=NA, "SEX"=NA), geo_level = "state", geo_code = 11){
  # year = year of census to call, default is 2022
  # vars = vector of numerical and categorical indexes associated with their names default is PWGTP, AGEP, and SEX
  # geo_level = geographic level Region, Division or State, default is all of the US 
  # geo_code = geographic code default is null as this is optional
  
  
  # Making variable choices align with instructions
  
  #Empty for now
  geo_str<-""
  
  # User input to upper/lower case
  # i made geo lower case because thats how it is in url
  names(vars) <- toupper(names(vars))
  geo_level <- tolower(geo)
  
  # All variable options
  n_valid_vars <- c("PWGTP", "AGEP", "GASP", "GRPIP", "JWAP", "JWDP", "JWMNP")
  c_valid_vars <- c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", "SEX")
  valid_level <- c("region", "division", "state")
  
  # Creating tibble of valid n and c var limits
  var_limits <- data.frame(names = c(n_valid_vars[-which(names(vars) == "PWGTP")], c_valid_vars), 
                          lower_bound = c(0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), 
                          upper_bound = c(99, 9999, 101, 285, 150, 200, 2, 5, 2, 12, 3, 24, 2))
  
  # Keep only those that appear in both
  n_var_names <- intersect(names(vars), n_valid_vars)
  c_var_names <- intersect(names(vars), c_valid_vars)
  
  # This checks that year is numeric, not multiple years and between '10 and '22
  if (!is.numeric(year) | length(year) != 1){
    stop("Warning: Year must be a single numeric value")
  } else if(year > 2022 | year < 2010){
    stop("Warning: Year must be between 2010-2022")
  }
  
  # Vars asked for in the set/at least 1 categorical
  if (length(n_var_names) == 0 | length(c_var_names) == 0){
    stop("Warning: One or more variables are invalid or not enough variables as argument")
  } 
  
  # Giving note if one of the variable calls is invalid and subsetting to valid variables
  if ((length(n_var_names) + length(c_var_names)) < length(names(vars))){
      print("Note: One or more variables are invalid, returning only valid variables")
    vars <- vars[c(n_var_names, c_var_names)]
  }

  # PWEGTP always included and at least one other numeric var
  if (length(n_var_names) < 2 | !("PWGTP" %in% n_var_names)){
    stop("Warning: PWGTP and at least 1 other valid numerical vector must be an argument")
  }
  
  # Assigning valid geo code based on selected region
  if (valid_level=="region"){
    valid_code <- c(1:4)
  } else if (valid_level=="division"){
      valid_code <- c(1:9)
  } else if (valid_level=="state"){
      valid_code <- c(1:56)[-c(3, 7, 14, 43, 52)] #i saw somewhere that it needs to be 01 not 1 in url but when i tested it it worked fine??? did  not test all single digits, idk if we need to include dc???
    # Just checked all the numbers in ST variable. For both 2010 and 2020 census data, the codes are all the values between 1 and 56 except 3, 7, 14, 43, and 52.
    # Also, just check all the valid 1 digit codes and it works without the 0 up front
  } 
  
  # Assigning valid indexes for variables
  #Cannot be indexed: PWGTP
  for (item in vars[-which(names(vars) == "PWGTP")]){
    if (!is.na(vars[item])){
      
      # Making sure given subset is an integer
      if (vars[item] != round(vars[item])){
        stop("Given subset must be an integer")
      }
      
      # Checking if given subset is within the bounds of the subset
      if (var_limits$lower_bound[which(var_limits$names == names(vars[item]))] > vars[item] | var_limits$upper_bound[which(var_limits$names == names(vars[item]))] < vars[item]){
        print(paste("Invalid Variable Subsetting. Returning all values of variable" + names(vars[item])))
        vars[item] = NA
      } else if ((names(vars[item]) %in% n_var_names)){
        print("Note: Numerical variable subsetted. While within the given range, Specific number may not be in the data")
      }
      

      
    }
  }
  
  # Fill geo_str  
  if (geo_level %in% valid_level && (geo_code %in% valid_code)){
    geo_str<-paste0("&for=",geo_level,":",geo_code)
  } else if (!(geo_level %in% valid_geo & geo_level != "all")){
      stop("Warning: Provided geography level is not valid")
  } else if (!(geo_code %in% valid_code)){
      stop("Warning: Provide geography code is not valid for your geography level")
  } else if (geo_level == "all"){
      geo_str<-paste0("&for=",us,":*")
  }
  
  # Need to go through api site and find suitable values for variable indexes and filter out bad values
    # I'm thinking that if they put in a bad value, we print a warning, but give them the variable without an index
  
  
  # Can't figure out how to do all the geography variables in one go. Will need to call multiple tables from the api and merge left with the "main variable tibble" 
  
  # i reread the forum seems like all means all of us and if they do not specify a division i.e they do region 1 vs region note default is without &for in url
#not sure if he wants 2 seperate variables or 1 im not sure how to seperate the string given covered material if he wants only 1 combined in put.
  main_var_url <- ifelse(!all(is.na(vars)), 
                    paste0("https://api.census.gov/data/", as.character(year), "/acs/acs1/pums?get=", 
                      paste(names(vars)[is.na(vars)], collapse=","), "&",
                      paste0(names(vars)[!is.na(vars)], "=", vars[!is.na(vars)], collapse="&")), 
                    paste0("https://api.census.gov/data/", as.character(year), "/acs/acs1/pums?get=", 
                      paste(names(vars)[is.na(vars)], collapse=","))
    )
  # Now to make the geography level urls. in the form of &for=geolevel:index
  
  # Use first function to make into tibbles
  main_var_tbl <- funct(main_var_url)
  geo_tbl <- funct(geo_url)
  
  # Merge left main_var, geo
  
}
```
